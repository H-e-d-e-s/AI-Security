{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#tensorflow 2.0\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cifar10, cifar100, fashion_mnist\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#tensorflow 2.0\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import cifar10, cifar100, fashion_mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D , UpSampling2D, Input\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "# numpy\n",
    "import numpy as np\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# art\n",
    "from art.estimators.classification.tensorflow import TensorFlowV2Classifier\n",
    "from art.attacks.evasion.boundary import BoundaryAttack\n",
    "from art.attacks.evasion.fast_gradient import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier\n",
    "\n",
    "import csv\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# load data and preprocess cifar10\n",
    "(x_train_cif10, y_train_cif10), (x_test_cif10, y_test_cif10) = cifar10.load_data()\n",
    "x_train_cif10 = x_train_cif10.astype(\"float32\") / 255\n",
    "x_test_cif10 = x_test_cif10.astype(\"float32\") / 255\n",
    "y_train_cif10 = to_categorical(y_train_cif10, num_classes=10)\n",
    "y_test_cif10 = to_categorical(y_test_cif10, num_classes=10)\n",
    "\n",
    "# load data and preprocess cifar100\n",
    "(x_train_cif100, y_train_cif100), (x_test_cif100, y_test_cif100) = cifar100.load_data()\n",
    "x_train_cif100 = x_train_cif100.astype(\"float32\") / 255\n",
    "x_test_cif100 = x_test_cif100.astype(\"float32\") / 255\n",
    "y_train_cif100 = to_categorical(y_train_cif100, num_classes=100)\n",
    "y_test_cif100 = to_categorical(y_test_cif100, num_classes=100)\n",
    "\n",
    "# load data and preprocess fashion_mnist\n",
    "(x_train_fmnist, y_train_fmnist), (x_test_fmnist, y_test_fmnist) = fashion_mnist.load_data()\n",
    "x_train_fmnist = x_train_fmnist.astype(\"float32\") / 255\n",
    "x_test_fmnist = x_test_fmnist.astype(\"float32\") / 255\n",
    "y_train_fmnist = to_categorical(y_train_fmnist, num_classes=10)\n",
    "y_test_fmnist = to_categorical(y_test_fmnist, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Create a model using TensorFlow\n",
    "print(\"Training model CIFAR10\")\n",
    "model_cif10 = Sequential([\n",
    "    Conv2D(32, 3, activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "    Conv2D(32, 3, activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "    Conv2D(32, 3, activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_cif10.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_cif10.fit(x_train_cif10, y_train_cif10, epochs=10, batch_size=64)\n",
    "score = model_cif10.evaluate(x_test_cif10, y_test_cif10, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "classifier_10 = KerasClassifier(\n",
    "    model=model_cif10,\n",
    "    clip_values=(0,1),\n",
    "    use_logits=False\n",
    ")\n",
    "\n",
    "model_cif100 = Sequential([\n",
    "    Conv2D(64, 3, activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "    Conv2D(64, 3, activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(100, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(\"Training model CIFAR100\")\n",
    "model_cif100.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_cif100.fit(x_train_cif100, y_train_cif100, epochs=10, batch_size=64)\n",
    "score = model_cif100.evaluate(x_test_cif100, y_test_cif100, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "\n",
    "model_fmnist = Sequential([\n",
    "    Conv2D(32, 3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    Conv2D(32, 3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    Conv2D(32, 3, activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "print(\"Training model Fashion MNIST\")\n",
    "model_fmnist.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "x_train_fmnist = x_train_fmnist.reshape(x_train_fmnist.shape[0], x_train_fmnist.shape[1], x_train_fmnist.shape[2], 1)\n",
    "x_test_fmnist = x_test_fmnist.reshape(x_test_fmnist.shape[0], x_test_fmnist.shape[1], x_test_fmnist.shape[2], 1)\n",
    "model_fmnist.fit(x_train_fmnist, y_train_fmnist, epochs=10, batch_size=64)\n",
    "score = model_fmnist.evaluate(x_test_fmnist, y_test_fmnist, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Attack the model using Fast Gradient Sign Method and Boundary Attack\n",
    "attack_FGSM_10 = FastGradientMethod(\n",
    "    estimator=classifier_10, \n",
    "    eps=0.3\n",
    "   )\n",
    "attack_Boundary_10 = BoundaryAttack(classifier_10)\n",
    "\n",
    "classifier_100 = KerasClassifier(\n",
    "    model=model_cif100,\n",
    "    clip_values=(0,1),\n",
    "    use_logits=False\n",
    ")\n",
    "\n",
    "classifier_fmnist = KerasClassifier(\n",
    "    model=model_fmnist,\n",
    "    clip_values=(0,1),\n",
    "    use_logits=False\n",
    ")\n",
    "attack_FGSM_100 = FastGradientMethod(\n",
    "    estimator=classifier_100,\n",
    "    eps=0.3\n",
    "    )\n",
    "attack_Boundary_100 = BoundaryAttack(classifier_100)\n",
    "\n",
    "attack_FGSM_fmnist = FastGradientMethod(\n",
    "    estimator=classifier_fmnist,\n",
    "    eps=0.3\n",
    "    )\n",
    "attack_Boundary_fmnist = BoundaryAttack(classifier_fmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Generate adversarial samples FGSM cifar10\n",
    "print(\"Generating adversarial samples for CIFAR10\")\n",
    "x_adv_FGSM_cif10 = []\n",
    "for i in range(10):\n",
    "    x_FGSM_10 = x_test_cif10[i][np.newaxis, :]  # add an additional dimension to the input data\n",
    "    y_FGSM_10= y_test_cif10[i]\n",
    "    x_adv_FGSM_cif10.append(attack_FGSM_10.generate(x=x_FGSM_10, y=y_FGSM_10))\n",
    "x_adv_FGSM_cif10= np.concatenate(x_adv_FGSM_cif10, axis=0)\n",
    "# Generate adversarial samples Boundary cifar10\n",
    "x_adv_BDRY_cif10 = []\n",
    "for i in range(10):\n",
    "    x_BDRY_10 = x_test_cif10[i][np.newaxis, :]  # add an additional dimension to the input data\n",
    "    y_BDRY_10 = y_test_cif10[i]\n",
    "    x_adv_BDRY_cif10.append(attack_Boundary_10.generate(x=x_BDRY_10, y=y_BDRY_10))\n",
    "x_adv_BDRY_cif10 = np.concatenate(x_adv_BDRY_cif10, axis=0)\n",
    "\n",
    "# Generate adversarial samples FGSM cifar100\n",
    "print(\"Generating adversarial samples for CIFAR100\")\n",
    "x_adv_FGSM_cif100 = []\n",
    "for i in range(10):\n",
    "    x_FGSM_100 = x_test_cif100[i][np.newaxis, :]  # add an additional dimension to the input data\n",
    "    y_FGSM_100= y_test_cif100[i]\n",
    "    x_adv_FGSM_cif100.append(attack_FGSM_100.generate(x=x_FGSM_100, y=y_FGSM_100))\n",
    "x_adv_FGSM_cif100 = np.concatenate(x_adv_FGSM_cif100, axis=0)\n",
    "# Generate adversarial samples Boundary cifar100\n",
    "x_adv_BDRY_cif100 = []\n",
    "for i in range(10):\n",
    "    x_BDRY_100 = x_test_cif100[i][np.newaxis, :]  # add an additional dimension to the input data\n",
    "    y_BDRY_100 = y_test_cif100[i]\n",
    "    x_adv_BDRY_cif100.append(attack_Boundary_100.generate(x=x_BDRY_100, y=y_BDRY_100))\n",
    "x_adv_BDRY_cif100 = np.concatenate(x_adv_BDRY_cif100, axis=0)\n",
    "\n",
    "# Generate adversarial samples FGSM fmnist\n",
    "print(\"Generating adversarial samples for Fashion MNIST\")\n",
    "x_adv_FGSM_fmnist = []\n",
    "for i in range(10):\n",
    "    x_FGSM_fmnist = x_test_fmnist[i][np.newaxis, :]  # add an additional dimension to the input data\n",
    "    y_FGSM_fmnist= y_test_fmnist[i]\n",
    "    x_adv_FGSM_fmnist.append(attack_FGSM_fmnist.generate(x=x_FGSM_fmnist, y=y_FGSM_fmnist))\n",
    "x_adv_FGSM_fmnist = np.concatenate(x_adv_FGSM_fmnist, axis=0)\n",
    "# Generate adversarial samples Boundary fmnist\n",
    "x_adv_BDRY_fmnist = []\n",
    "for i in range(10):\n",
    "    x_BDRY_fmnist = x_test_fmnist[i][np.newaxis, :]  # add an additional dimension to the input data\n",
    "    y_BDRY_fmnist = y_test_fmnist[i]\n",
    "    x_adv_BDRY_fmnist.append(attack_Boundary_fmnist.generate(x=x_BDRY_fmnist, y=y_BDRY_fmnist))\n",
    "x_adv_BDRY_fmnist = np.concatenate(x_adv_BDRY_fmnist, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# plot 10 images and their adversarial counter parts using FGSM : cifar10\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_cif10[i])\n",
    "    axes[1, i].imshow(x_adv_FGSM_cif10[i])\n",
    "plt.title(\"FGSM\")\n",
    "fig.savefig('10imgFGSM.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the difference between the original and adversarial images : cifar10\n",
    "fig, axes = plt.subplots(1, 10, figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(x_adv_FGSM_cif10[i] - x_test_cif10[i])\n",
    "plt.title(\"FGSM Difference\")\n",
    "fig.savefig('10imgFGSMDiff.png')\n",
    "plt.show()\n",
    "\n",
    "# plot 10 images and their adversarial counter parts using Boundary : cifar10\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_cif10[i])\n",
    "    axes[1, i].imshow(x_adv_BDRY_cif10[i])\n",
    "plt.title(\"Boundary Attack\")\n",
    "fig.savefig('10imgBDRY.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the difference between the original and adversarial images : cifar10\n",
    "fig, axes = plt.subplots(1, 10, figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(x_adv_BDRY_cif10[i] - x_test_cif10[i])\n",
    "plt.title(\"Boundary Difference\")\n",
    "fig.savefig('10imgBDRYDiff.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the image and its label side by side with the adversarial image and its label using FGSM with the name of the class : cifar10\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_cif10[i])\n",
    "    axes[1, i].imshow(x_adv_FGSM_cif10[i])\n",
    "    axes[0, i].set_title(class_names[np.argmax(y_test_cif10[i])])\n",
    "    axes[1, i].set_title(class_names[np.argmax(classifier_10.predict(x_adv_FGSM_cif10[i][np.newaxis, :]))])\n",
    "fig.suptitle('FGSM', fontsize=16)\n",
    "fig.savefig('10imgFGSMClass.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the image and its label side by side with the adversarial image and its label using Boundary with the name of the class : cifar10\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_cif10[i])\n",
    "    axes[1, i].imshow(x_adv_BDRY_cif10[i])\n",
    "    axes[0, i].set_title(class_names[np.argmax(y_test_cif10[i])])\n",
    "    axes[1, i].set_title(class_names[np.argmax(classifier_10.predict(x_adv_BDRY_cif10[i][np.newaxis, :]))])\n",
    "fig.suptitle('Boundary Attack', fontsize=16)\n",
    "fig.savefig('10imgBDRYClass.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# plot 10 images and their adversarial counter parts using FGSM : cifar100\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_cif100[i])\n",
    "    axes[1, i].imshow(x_adv_FGSM_cif100[i])\n",
    "plt.title(\"FGSM Attack\")\n",
    "fig.savefig('10imgFGSM100.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the difference between the original and adversarial images : cifar100\n",
    "fig, axes = plt.subplots(1, 10, figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(x_adv_FGSM_cif100[i] - x_test_cif100[i])\n",
    "plt.title(\"FGSM Difference\")\n",
    "fig.savefig('10imgFGSMDiff100.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the image and its label side by side with the adversarial image and its label using FGSM with the name of the class : cifar100\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "cifar100_labels = [\n",
    "'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
    "'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
    "'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
    "'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
    "'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "'worm'\n",
    "]\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_cif100[i])\n",
    "    axes[1, i].imshow(x_adv_FGSM_cif100[i])\n",
    "    axes[0, i].set_title(cifar100_labels[np.argmax(y_test_cif100[i])])\n",
    "    axes[1, i].set_title(cifar100_labels[np.argmax(classifier_100.predict(x_adv_FGSM_cif100[i][np.newaxis, :]))])\n",
    "fig.suptitle('FGSM', fontsize=16)\n",
    "fig.savefig('10imgFGSMClass100.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the image and its label side by side with the adversarial image and its label using Boundary with the name of the class : cifar100\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "cifar100_labels = [\n",
    "'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
    "'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
    "'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
    "'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
    "'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "'worm'\n",
    "]\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_cif100[i])\n",
    "    axes[1, i].imshow(x_adv_BDRY_cif100[i])\n",
    "    axes[0, i].set_title(cifar100_labels[np.argmax(y_test_cif100[i])])\n",
    "    axes[1, i].set_title(cifar100_labels[np.argmax(classifier_100.predict(x_adv_BDRY_cif100[i][np.newaxis, :]))])\n",
    "fig.suptitle('Boundary Attack', fontsize=16)\n",
    "fig.savefig('10imgBDRYClass100.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# plot 10 images and their adversarial counter parts using FGSM : fashion mnist\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_fmnist[i])\n",
    "    axes[1, i].imshow(x_adv_FGSM_fmnist[i])\n",
    "plt.title(\"FGSM Attack\")\n",
    "fig.savefig('10imgFGSMfmnist.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the difference between the original and adversarial images : fashion mnist\n",
    "fig, axes = plt.subplots(1, 10, figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(x_adv_FGSM_fmnist[i] - x_test_fmnist[i])\n",
    "plt.title(\"FGSM Difference\")\n",
    "fig.savefig('10imgFGSMDifffmnist.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the image and its label side by side with the adversarial image and its label using FGSM with the name of the class : fashion mnist\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_fmnist[i])\n",
    "    axes[1, i].imshow(x_adv_FGSM_fmnist[i])\n",
    "    axes[0, i].set_title(class_names[np.argmax(y_test_fmnist[i])])\n",
    "    axes[1, i].set_title(class_names[np.argmax(classifier_fmnist.predict(x_adv_FGSM_fmnist[i][np.newaxis, :]))])\n",
    "fig.suptitle('FGSM', fontsize=16)\n",
    "fig.savefig('10imgFGSMClassfmnist.png')\n",
    "plt.show()\n",
    "\n",
    "# plot the image and its label side by side with the adversarial image and its label using Boundary with the name of the class : fashion mnist\n",
    "fig, axes = plt.subplots(2, 10, figsize=(10, 2))\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(x_test_fmnist[i])\n",
    "    axes[1, i].imshow(x_adv_BDRY_fmnist[i])\n",
    "    axes[0, i].set_title(class_names[np.argmax(y_test_fmnist[i])])\n",
    "    axes[1, i].set_title(class_names[np.argmax(classifier_fmnist.predict(x_adv_BDRY_fmnist[i][np.newaxis, :]))])\n",
    "fig.suptitle('Boundary Attack', fontsize=16)\n",
    "fig.savefig('10imgBDRYClassfmnist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_FGSM_cif10 = classifier_10.predict(x_adv_FGSM_cif10)\n",
    "predictions_BDRY_cif10 = classifier_10.predict(x_adv_BDRY_cif10)\n",
    "predictions_FGSM_cif100 = classifier_100.predict(x_adv_FGSM_cif100)\n",
    "predictions_BDRY_cif100 = classifier_100.predict(x_adv_BDRY_cif100)\n",
    "predictions_FGSM_fmnist = classifier_fmnist.predict(x_adv_FGSM_fmnist)\n",
    "predictions_BDRY_fmnist = classifier_fmnist.predict(x_adv_BDRY_fmnist)\n",
    "\n",
    "# Attack success rate CIFAR10\n",
    "print(\"Attack success rate for FGSM attack CIFAR10: \", np.sum(np.argmax(predictions_FGSM_cif10, axis=1) != np.argmax(y_test_cif10[:10], axis=1)) / 10)\n",
    "print(\"Attack success rate for Boundary attack CIFAR10: \", np.sum(np.argmax(predictions_BDRY_cif10, axis=1) != np.argmax(y_test_cif10[:10], axis=1)) / 10)\n",
    "\n",
    "# Attack success rate CIFAR100\n",
    "print(\"Attack success rate for FGSM attack CIFAR100: \", np.sum(np.argmax(predictions_FGSM_cif100, axis=1) != np.argmax(y_test_cif100[:10], axis=1)) / 10)\n",
    "print(\"Attack success rate for Boundary attack CIFAR100: \", np.sum(np.argmax(predictions_BDRY_cif100, axis=1) != np.argmax(y_test_cif100[:10], axis=1)) / 10)\n",
    "\n",
    "# Attack success rate fashion mnist\n",
    "print(\"Attack success rate for FGSM attack fashion mnist: \", np.sum(np.argmax(predictions_FGSM_fmnist, axis=1) != np.argmax(y_test_fmnist[:10], axis=1)) / 10)\n",
    "print(\"Attack success rate for Boundary attack fashion mnist: \", np.sum(np.argmax(predictions_BDRY_fmnist, axis=1) != np.argmax(y_test_fmnist[:10], axis=1)) / 10)\n",
    "\n",
    "\n",
    "# F1 score for FGSM attack and Boundary attack CIFAR10\n",
    "print(\"F1 score for FGSM attack CIFAR10: \", f1_score(np.argmax(y_test_cif10[:10], axis=1), np.argmax(predictions_FGSM_cif10, axis=1), average='macro'))\n",
    "print(\"F1 score for Boundary attack CIFAR10: \", f1_score(np.argmax(y_test_cif10[:10], axis=1), np.argmax(predictions_BDRY_cif10, axis=1), average='macro'))\n",
    "\n",
    "# F1 score for FGSM attack and Boundary attack CIFAR100\n",
    "print(\"F1 score for FGSM attack CIFAR100: \", f1_score(np.argmax(y_test_cif100[:10], axis=1), np.argmax(predictions_FGSM_cif100, axis=1), average='macro'))\n",
    "print(\"F1 score for Boundary attack CIFAR100: \", f1_score(np.argmax(y_test_cif100[:10], axis=1), np.argmax(predictions_BDRY_cif100, axis=1), average='macro'))\n",
    "\n",
    "# F1 score for FGSM attack and Boundary attack fashion mnist\n",
    "print(\"F1 score for FGSM attack fashion mnist: \", f1_score(np.argmax(y_test_fmnist[:10], axis=1), np.argmax(predictions_FGSM_fmnist, axis=1), average='macro'))\n",
    "print(\"F1 score for Boundary attack fashion mnist: \", f1_score(np.argmax(y_test_fmnist[:10], axis=1), np.argmax(predictions_BDRY_fmnist, axis=1), average='macro'))\n",
    "\n",
    "#accuracy of the FGSM attack and Boundary attack CIFAR10\n",
    "print(\"Accuracy of the FGSM attack CIFAR10: \", accuracy_score(np.argmax(y_test_cif10[:10], axis=1), np.argmax(predictions_FGSM_cif10, axis=1)))\n",
    "print(\"Accuracy of the Boundary attack CIFAR10: \", accuracy_score(np.argmax(y_test_cif10[:10], axis=1), np.argmax(predictions_BDRY_cif10, axis=1)))\n",
    "\n",
    "#accuracy of the FGSM attack and Boundary attack CIFAR100\n",
    "print(\"Accuracy of the FGSM attack CIFAR100: \", accuracy_score(np.argmax(y_test_cif100[:10], axis=1), np.argmax(predictions_FGSM_cif100, axis=1)))\n",
    "print(\"Accuracy of the Boundary attack CIFAR100: \", accuracy_score(np.argmax(y_test_cif100[:10], axis=1), np.argmax(predictions_BDRY_cif100, axis=1)))\n",
    "\n",
    "#accuracy of the FGSM attack and Boundary attack fashion mnist\n",
    "print(\"Accuracy of the FGSM attack fashion mnist: \", accuracy_score(np.argmax(y_test_fmnist[:10], axis=1), np.argmax(predictions_FGSM_fmnist, axis=1)))\n",
    "print(\"Accuracy of the Boundary attack fashion mnist: \", accuracy_score(np.argmax(y_test_fmnist[:10], axis=1), np.argmax(predictions_BDRY_fmnist, axis=1)))\n",
    "\n",
    "#precision of the FGSM attack and Boundary attack CIFAR10\n",
    "print(\"Precision of the FGSM attack CIFAR10: \", precision_score(np.argmax(y_test_cif10[:10], axis=1), np.argmax(predictions_FGSM_cif10, axis=1), average='macro'))\n",
    "print(\"Precision of the Boundary attack CIFAR10: \", precision_score(np.argmax(y_test_cif10[:10], axis=1), np.argmax(predictions_BDRY_cif10, axis=1), average='macro'))\n",
    "\n",
    "#precision of the FGSM attack and Boundary attack CIFAR100\n",
    "print(\"Precision of the FGSM attack CIFAR100: \", precision_score(np.argmax(y_test_cif100[:10], axis=1), np.argmax(predictions_FGSM_cif100, axis=1), average='macro'))\n",
    "print(\"Precision of the Boundary attack CIFAR100: \", precision_score(np.argmax(y_test_cif100[:10], axis=1), np.argmax(predictions_BDRY_cif100, axis=1), average='macro'))\n",
    "\n",
    "#precision of the FGSM attack and Boundary attack fashion mnist\n",
    "print(\"Precision of the FGSM attack fashion mnist: \", precision_score(np.argmax(y_test_fmnist[:10], axis=1), np.argmax(predictions_FGSM_fmnist, axis=1), average='macro'))\n",
    "print(\"Precision of the Boundary attack fashion mnist: \", precision_score(np.argmax(y_test_fmnist[:10], axis=1), np.argmax(predictions_BDRY_fmnist, axis=1), average='macro'))\n",
    "\n",
    "#recall of the FGSM attack and Boundary attack CIFAR10\n",
    "print(\"Recall of the FGSM attack CIFAR10: \", recall_score(np.argmax(y_test_cif10[:10], axis=1), np.argmax(predictions_FGSM_cif10, axis=1), average='macro'))\n",
    "print(\"Recall of the Boundary attack CIFAR10: \", recall_score(np.argmax(y_test_cif10[:10], axis=1), np.argmax(predictions_BDRY_cif10, axis=1), average='macro'))\n",
    "\n",
    "#recall of the FGSM attack and Boundary attack CIFAR100\n",
    "print(\"Recall of the FGSM attack CIFAR100: \", recall_score(np.argmax(y_test_cif100[:10], axis=1), np.argmax(predictions_FGSM_cif100, axis=1), average='macro'))\n",
    "print(\"Recall of the Boundary attack CIFAR100: \", recall_score(np.argmax(y_test_cif100[:10], axis=1), np.argmax(predictions_BDRY_cif100, axis=1), average='macro'))\n",
    "\n",
    "#recall of the FGSM attack and Boundary attack fashion mnist\n",
    "print(\"Recall of the FGSM attack fashion mnist: \", recall_score(np.argmax(y_test_fmnist[:10], axis=1), np.argmax(predictions_FGSM_fmnist, axis=1), average='macro'))\n",
    "print(\"Recall of the Boundary attack fashion mnist: \", recall_score(np.argmax(y_test_fmnist[:10], axis=1), np.argmax(predictions_BDRY_fmnist, axis=1), average='macro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DQN architecture\n",
    "def create_dqn(input_shape, num_actions):\n",
    "   inputs = Input(shape=input_shape)\n",
    "   layer = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "   layer = Conv2D(64, kernel_size=(3, 3), activation='relu')(layer)\n",
    "   layer = Flatten()(layer)\n",
    "   layer = Dense(64, activation='relu')(layer)\n",
    "   outputs = Dense(num_actions, activation='linear')(layer)\n",
    "   model = Model(inputs=inputs, outputs=outputs)\n",
    "   model.compile(optimizer='adam', loss='mse')\n",
    "   return model\n",
    "\n",
    "# Define the environment\n",
    "class AdversarialDetectionEnv:\n",
    "   def __init__(self, classifier, x_clean, x_adv, y_true):\n",
    "       self.classifier = classifier\n",
    "       self.x_clean = x_clean\n",
    "       self.x_adv = x_adv\n",
    "       self.y_true = y_true\n",
    "       self.action_space = 2 # 0 for clean, 1 for adversarial\n",
    "       self.state = None\n",
    "       self.reset()\n",
    "\n",
    "   def reset(self):\n",
    "       # Randomly select a clean or adversarial example as the initial state\n",
    "       is_adv = random.choice([0, 1])\n",
    "       idx = random.randint(0, min(len(self.x_clean) - 1, len(self.x_adv) - 1))\n",
    "       self.state = self.x_adv[idx] if is_adv else self.x_clean[idx]\n",
    "       return self.state\n",
    "\n",
    "\n",
    "   def step(self, action):\n",
    "        # Use the classifier to predict the label of the current state\n",
    "        pred = self.classifier.predict(self.state[np.newaxis, :])\n",
    "        label = np.argmax(pred, axis=1)\n",
    "        true_label = np.argmax(self.y_true, axis=1)\n",
    "        # Check if the classifier's prediction is correct\n",
    "        is_correct = np.all(label == true_label)\n",
    "        # Define the reward based on the action and correctness of the prediction\n",
    "        if action == 0 and is_correct: # Predicted as clean and is correct\n",
    "            reward = 1\n",
    "        elif action == 1 and not is_correct: # Predicted as adversarial and is correct\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "        # Get the next state\n",
    "        next_state = self.reset()\n",
    "        done = False # For simplicity, we don't define an episode end condition\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "# Instantiate the environments\n",
    "env_cif10 = AdversarialDetectionEnv(classifier_10, x_train_cif10, x_adv_FGSM_cif10, y_train_cif10)\n",
    "env_cif100 = AdversarialDetectionEnv(classifier_100, x_train_cif100, x_adv_FGSM_cif100, y_train_cif100)\n",
    "env_fmnist = AdversarialDetectionEnv(classifier_fmnist, x_train_fmnist, x_adv_FGSM_fmnist, y_train_fmnist)\n",
    "\n",
    "# Instantiate the DQNs\n",
    "input_shape_10 = env_cif10.state.shape\n",
    "num_actions_10 = env_cif10.action_space\n",
    "dqn_cif10 = create_dqn(input_shape_10, num_actions_10)\n",
    "\n",
    "input_shape_100 = env_cif100.state.shape\n",
    "num_actions_100 = env_cif100.action_space\n",
    "dqn_cif100 = create_dqn(input_shape_100, num_actions_100)\n",
    "\n",
    "input_shape_fmnist = env_fmnist.state.shape\n",
    "num_actions_fmnist = env_fmnist.action_space\n",
    "\n",
    "dqn_fmnist = create_dqn(input_shape_fmnist, num_actions_fmnist)\n",
    "\n",
    "# Train the DQNs\n",
    "memory = deque(maxlen=1000)\n",
    "epsilon = 1.0 # Exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.99\n",
    "batch_size = 4\n",
    "\n",
    "for episode in range(1000):\n",
    "   state = env_cif10.reset()\n",
    "   state = np.expand_dims(state, axis=0)\n",
    "   done = False\n",
    "   while not done:\n",
    "       # Epsilon-greedy action selection\n",
    "       if np.random.rand() <= epsilon:\n",
    "           action = random.randrange(num_actions_10)\n",
    "       else:\n",
    "           action_values = dqn_cif10.predict(state)\n",
    "           action = np.argmax(action_values[0])\n",
    "\n",
    "       next_state, reward, done, _ = env_cif10.step(action)\n",
    "       next_state = np.expand_dims(next_state, axis=0)\n",
    "\n",
    "       # Store the experience in memory\n",
    "       memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "       state = next_state\n",
    "\n",
    "       # Experience replay\n",
    "       if len(memory) > batch_size:\n",
    "           minibatch = random.sample(memory, batch_size)\n",
    "           for state, action, reward, next_state, done in minibatch:\n",
    "               target = reward\n",
    "               if not done:\n",
    "                  target = reward + 0.95 * np.amax(dqn_cif10.predict(next_state)[0])\n",
    "               target_f = dqn_cif10.predict(state)\n",
    "               target_f[0][action] = target\n",
    "               dqn_cif10.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "   # Update epsilon\n",
    "   if epsilon > epsilon_min:\n",
    "       epsilon *= epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the DQNs\n",
    "memory = deque(maxlen=1000)\n",
    "epsilon = 1.0 # Exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.99\n",
    "batch_size = 4\n",
    "\n",
    "for episode in range(1000):\n",
    "   state = env_cif100.reset()\n",
    "   state = np.expand_dims(state, axis=0)\n",
    "   done = False\n",
    "   while not done:\n",
    "       # Epsilon-greedy action selection\n",
    "       if np.random.rand() <= epsilon:\n",
    "           action = random.randrange(num_actions_100)\n",
    "       else:\n",
    "           action_values = dqn_cif100.predict(state)\n",
    "           action = np.argmax(action_values[0])\n",
    "\n",
    "       next_state, reward, done, _ = env_cif100.step(action)\n",
    "       next_state = np.expand_dims(next_state, axis=0)\n",
    "\n",
    "       # Store the experience in memory\n",
    "       memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "       state = next_state\n",
    "\n",
    "       # Experience replay\n",
    "       if len(memory) > batch_size:\n",
    "           minibatch = random.sample(memory, batch_size)\n",
    "           for state, action, reward, next_state, done in minibatch:\n",
    "               target = reward\n",
    "               if not done:\n",
    "                  target = reward + 0.95 * np.amax(dqn_cif100.predict(next_state)[0])\n",
    "               target_f = dqn_cif100.predict(state)\n",
    "               target_f[0][action] = target\n",
    "               dqn_cif100.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "   # Update epsilon\n",
    "   if epsilon > epsilon_min:\n",
    "       epsilon *= epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the DQNs\n",
    "memory = deque(maxlen=1000)\n",
    "epsilon = 1.0 # Exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.99\n",
    "batch_size = 4\n",
    "\n",
    "for episode in range(1000):\n",
    "   state = env_fmnist.reset()\n",
    "   state = np.expand_dims(state, axis=0)\n",
    "   done = False\n",
    "   while not done:\n",
    "       # Epsilon-greedy action selection\n",
    "       if np.random.rand() <= epsilon:\n",
    "           action = random.randrange(num_actions_fmnist)\n",
    "       else:\n",
    "           action_values = dqn_fmnist.predict(state)\n",
    "           action = np.argmax(action_values[0])\n",
    "\n",
    "       next_state, reward, done, _ = env_fmnist.step(action)\n",
    "       next_state = np.expand_dims(next_state, axis=0)\n",
    "\n",
    "       # Store the experience in memory\n",
    "       memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "       state = next_state\n",
    "\n",
    "       # Experience replay\n",
    "       if len(memory) > batch_size:\n",
    "           minibatch = random.sample(memory, batch_size)\n",
    "           for state, action, reward, next_state, done in minibatch:\n",
    "               target = reward\n",
    "               if not done:\n",
    "                  target = reward + 0.95 * np.amax(dqn_fmnist.predict(next_state)[0])\n",
    "               target_f = dqn_fmnist.predict(state)\n",
    "               target_f[0][action] = target\n",
    "               dqn_fmnist.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "   # Update epsilon\n",
    "   if epsilon > epsilon_min:\n",
    "       epsilon *= epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder architecture\n",
    "def create_autoencoder(input_shape):\n",
    "   inputs = Input(shape=input_shape)\n",
    "   # Encoder\n",
    "   encoded = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "   encoded = MaxPooling2D((2, 2), padding='same')(encoded)\n",
    "   # Decoder\n",
    "   decoded = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "   decoded = UpSampling2D((2, 2))(decoded)\n",
    "   decoded = Conv2D(input_shape[-1], (3, 3), activation='sigmoid', padding='same')(decoded)\n",
    "   # Autoencoder\n",
    "   autoencoder = Model(inputs, decoded)\n",
    "   autoencoder.compile(optimizer='adam', loss='mse')\n",
    "   return autoencoder\n",
    "\n",
    "# Instantiate the autoencoders\n",
    "input_shape_cif10 = (32, 32, 3) # Example input shape for CIFAR-10\n",
    "autoencoder_cif10 = create_autoencoder(input_shape_cif10)\n",
    "\n",
    "input_shape_cif100 = (32, 32, 3) # Example input shape for CIFAR-100\n",
    "autoencoder_cif100 = create_autoencoder(input_shape_cif100)\n",
    "\n",
    "input_shape_fmnist = (28, 28, 1) # Example input shape for Fashion-MNIST\n",
    "autoencoder_fmnist = create_autoencoder(input_shape_fmnist)\n",
    "\n",
    "# Train the autoencoders on clean data\n",
    "autoencoder_cif10.fit(x_train_cif10, x_train_cif10, epochs=50, batch_size=256, shuffle=True)\n",
    "autoencoder_cif100.fit(x_train_cif100, x_train_cif100, epochs=50, batch_size=256, shuffle=True)\n",
    "autoencoder_fmnist.fit(x_train_fmnist, x_train_fmnist, epochs=50, batch_size=256, shuffle=True)\n",
    "\n",
    "# Use the trained DQNs to detect adversarial inputs and the autoencoders to restore them\n",
    "def restore_adversarial_inputs(dqn, autoencoder, x_adv, threshold=0.5):\n",
    "  restored_images = []\n",
    "  for x in x_adv:\n",
    "      x = np.expand_dims(x, axis=0)\n",
    "      action_values = dqn.predict(x)\n",
    "      action = np.argmax(action_values[0])\n",
    "      if action == 1: # The DQN predicts this is an adversarial input\n",
    "          print(\"Detected adversarial input.\")\n",
    "          restored = autoencoder.predict(x)\n",
    "          restored_images.append(restored.squeeze()) # Remove batch dimension\n",
    "      else:\n",
    "          print(\"Did not detect adversarial input.\")\n",
    "          restored_images.append(x.squeeze())\n",
    "  return np.array(restored_images)\n",
    "\n",
    "# Example usage for CIFAR-10\n",
    "x_adv_detected_cif10 = restore_adversarial_inputs(dqn_cif10, autoencoder_cif10, x_adv_FGSM_cif10)\n",
    "x_adv_detected_cif100 = restore_adversarial_inputs(dqn_cif100, autoencoder_cif100, x_adv_FGSM_cif100)\n",
    "x_adv_detected_fmnist = restore_adversarial_inputs(dqn_fmnist, autoencoder_fmnist, x_adv_FGSM_fmnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot original and adversarial images\n",
    "def plot_images(original, adversarial, title):\n",
    "   fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "   \n",
    "   # Plot original image\n",
    "   axes[0].imshow(original)\n",
    "   axes[0].set_title('Original Image')\n",
    "   axes[0].axis('off')\n",
    "   \n",
    "   # Plot adversarial image\n",
    "   axes[1].imshow(adversarial)\n",
    "   axes[1].set_title('Adversarial Image')\n",
    "   axes[1].axis('off')\n",
    "   \n",
    "   plt.suptitle(title)\n",
    "   plt.show()\n",
    "\n",
    "# Choose some adversarial examples to visualize\n",
    "indexes = random.sample(range(len(x_adv_FGSM_cif10)), 10)\n",
    "\n",
    "# Visualize original and adversarial images\n",
    "for idx in indexes:\n",
    "   original = x_train_cif10[idx]\n",
    "   adversarial = x_adv_FGSM_cif10[idx]\n",
    "   restored = restore_adversarial_inputs(dqn_cif10, autoencoder_cif10, [adversarial])[0]\n",
    "   plot_images(original, adversarial, 'Original vs Adversarial')\n",
    "   plot_images(original, restored, 'Original vs Restored')\n",
    "\n",
    "\n",
    "# Compute accuracy on original and adversarial images\n",
    "original_preds = classifier_10.predict(x_train_cif10[:10])\n",
    "adversarial_preds = classifier_10.predict(x_adv_FGSM_cif10[:10])\n",
    "original_acc = accuracy_score(y_train_cif10[:10], np.argmax(original_preds, axis=1))\n",
    "adversarial_acc = accuracy_score(y_train_cif10[:10], np.argmax(adversarial_preds, axis=1))\n",
    "print(f\"Original Accuracy: {original_acc}\")\n",
    "print(f\"Adversarial Accuracy: {adversarial_acc}\")\n",
    "\n",
    "# Compute accuracy on original and restored images\n",
    "restored_preds = classifier_10.predict(x_adv_detected_cif10[:10])\n",
    "restored_acc = accuracy_score(y_train_cif10[:10], np.argmax(restored_preds, axis=1))\n",
    "print(f\"Restored Accuracy: {restored_acc}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
